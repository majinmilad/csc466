# Reflection

## Data Used and Motivation

For my recommender, I use an implicit feedback signal derived from **content view events**. A temporal split was performed creating an 80/20 split, and from the training partition I only count a view as a meaningful interaction if it is a *qualified view*, defined by a **watch ratio threshold** (specifically watch_ratio ≥ 0.60). I chose qualified views because they better represent true engagement than partial clicks or shorter sampling behavior.

The recommender is a conventional memory-based, item-item collaborative filtering model, so the data it uses is simply the interaction behavior between users and items. After filtering for watch ratio, I aggregate interactions into a simple but effective strength signal: for each `(adventurer, content)` pair, the strength is the number of qualified views in the training window. This approach allows repeat engagement to contribute more heavily while avoiding the need for explicit signal or more complex accounting. Neighbors are defined between items and items with more similar user behavior are deemed closer together. The repeat engagement metric comes into use as a weight when calculating recommendation scores for items.

I choose this approach because I felt that user watch behavior was likely one of the strongest (if not the strongest) signals for content preference and engagement. Collaborative filtering's straightforward approach towards leaning directly on interaction felt appropriate.

## Which Adventurers the Recommender Serves Well

The recommender serves **warm adventurers** best, meaning users who have multiple qualified interactions during the training period. Because the model is based on **item-item collaborative filtering**, it relies on previously consumed items to lead toward similar content. When an adventurer has watched several items with high watch ratios, the model can reliably identify strong consumption patterns across users.

The recommender also performs well when an adventurer’s viewing history is relatively coherent. In these cases, the neighborhoods of multiple watched items tend to overlap, causing certain candidate items to receive score contributions from multiple sources and rise to the top of the recommendation list. If there is a large volume of coherent history then the recommender has more reliable signal to learn from.

## Which Adventurers the Recommender Does Not Serve Well

The recommender does not serve **cold-start users** well. Adventurers with little or no qualified viewing history are not suitable candidates. Since recommendations are generated by propagating similarity from items a user has already consumed, insufficient history results in weak or altogether missing recommendations. A completely cold user can not get any recommendations from this model, while a user who appears in the train split but not in the test has no offline-evaluation value.

Additionally, the model can struggle with users whose behavior is dominated by low watch-ratio sampling, since those interactions are filtered out entirely. Finally, content items that are rare or new in the training data are less likely to be recommended, as they lack strong neighborhood structure in the item similarity space. Items which do not appear in the train set as part of a qualified interaction also cannot be recommended ever.

## Why These Three Adventurers Were Chosen

For the evaluation portion, I selected the publisher `rw94` (**Starlit Enterprises**) because it had multiple **current subscribers** who are also well-served by my recommender. These adventurers appear in the qualified training user set and retain at least two strong recommendations after considering for the requirement that recommended content must be **content they have never viewed**.

From this publisher, I chose the following three adventurers:

- **`1ryr`** → recommendations: `svzv`, `w9ue`  
- **`g1wj`** → recommendations: `xr7w`, `3wc5`  
- **`mjr1`** → recommendations: `hm3u`, `izra`  

These users were selected because they have sufficient qualified viewing history to support stable collaborative filtering recommendations and satisfy all imposed constraints.

## Why the Recommender Chose These Content Items

The recommender generates scores by expanding outward from each adventurer’s qualified viewing history. For each item the adventurer has watched, the model retrieves its nearest neighbors using cosine similarity in an item-by-user space. Each candidate item receives a score contribution equal to **(similarity × interaction strength)**, and these contributions are summed across all items in the adventurer’s history thereby creating the weighted similarity score.

Items that are similar to **multiple** previously watched items receive multiple score contributions and therefore rank higher. Additionally, items associated with stronger engagement (repeat qualified views) exert a greater influence on the final ranking. The recommended items listed above emerged because they were consistently similar to the most strongly engaged items in each adventurer’s history. All recommendations were further filtered to ensure that none of the recommended content appears anywhere in the adventurer’s viewing history, providing only recommendations for content they hadn't previously viewed.

Ultimately, the collaborative filter model decides on item similarity based on the items having similar user vectors, and so these items recommended are a combination of having user overlap and having strong user engagement.
